{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514fffaf-36ee-4deb-802b-4685c2dcb1c6",
   "metadata": {},
   "source": [
    "# Lab-05: Visualizing tweets from the 2020 US presidential election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b82dc807-629b-47e6-997d-c77bfb105cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Dataset is a randomly sampled subset of: https://www.kaggle.com/manchunhui/us-election-2020-tweets\n",
    "trump = pd.read_csv(\"2020_tweets_trump.csv\", lineterminator='\\n')\n",
    "biden = pd.read_csv(\"2020_tweets_biden.csv\", lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbac270-263e-4481-b7b6-a08aee76a7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biden), len(trump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f5d88e-ae90-41cf-be32-00579cf35fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = 10000\n",
    "trump = trump.sample(n=M//2)\n",
    "biden = biden.sample(n=M//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50310e26-a410-42a1-81fb-be0b5ac32905",
   "metadata": {},
   "outputs": [],
   "source": [
    "biden_tweets = biden['tweet'].tolist()\n",
    "trump_tweets = trump['tweet'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef537b0e-ca78-44af-bce3-0a9a21ba79d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'there better be SEVERAL #Biden fancams with Nicki songs.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_tweets[3023]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb3b36a-9598-4efb-b3ad-b0cccd331bb2",
   "metadata": {},
   "source": [
    "# Preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d4a8f95-2929-404c-bc7e-695b617f883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "from typing import List\n",
    "\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "pipeline_name = '2020ElectionTweets'\n",
    "\n",
    "\n",
    "def camel_case_split(str):\n",
    "    \"\"\" This function turns in #Biden2020 into Biden 2020 \"\"\"\n",
    "    return \" \".join([wrd for wrd in re.findall(r'[A-Z](?:[a-z]+|[A-Z]*(?=[A-Z]|$))', str)])\n",
    "\n",
    "\n",
    "@Language.component(pipeline_name)\n",
    "def preprocess(doc):\n",
    "    doc = [token for token in doc if not token.is_punct]\n",
    "    # doc = [token for token in doc if not token.is_stop]\n",
    "    doc = [token.text.lower().strip() for token in doc]\n",
    "    doc = [token for token in doc if 0 < len(token) <= 12]\n",
    "    return \" \".join(doc)\n",
    "\n",
    "\n",
    "class Pipeline:\n",
    "    \n",
    "    # http://emailregex.com/\n",
    "    email_re = r\"\"\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)\n",
    "    *|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]\n",
    "    |\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9]\n",
    "    (?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.){3}\n",
    "    (?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:\n",
    "    (?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\"\"\"\n",
    "    # replace = [ (pattern-to-replace, replacement),  ...]\n",
    "    replace = [\n",
    "        (\"<[^>]*>\", \" \"),\n",
    "        (email_re, \" \"),                           # Matches emails\n",
    "        (r\"(?<=\\d),(?=\\d)\", \"\"),                   # Remove commas in numbers\n",
    "        (r\"\\d+\", \" \"),                             # Map digits to special token <numbr>\n",
    "        (r\"[*\\^\\.$&@<>,\\-/+{|}=?#:;'\\\"\\[\\]]\", \"\"), # Punctuation and other junk\n",
    "        (r\"[\\n\\t\\r]\", \" \"),                        # Removes newlines, tabs, creturn\n",
    "        (r\"[^\\x00-\\x7F]+\", \"\"),                    # Removes non-ascii chars\n",
    "        (r\"\\\\+\", \" \"),                             # Removes double-backslashs\n",
    "        (r\"\\s+n\\s+\", \" \"),                         # 'n' leftover from \\\\n\n",
    "        (r\"\\s+\", \" \")                              # Strips extra whitespace\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pipeline = spacy.load('en_core_web_sm')\n",
    "        self.pipeline.add_pipe(pipeline_name);\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.transform(*args, **kwargs)\n",
    "\n",
    "    def transform(self, doc: str):\n",
    "        for repl in self.replace:\n",
    "            doc = re.sub(repl[0], repl[1], doc)\n",
    "        doc = camel_case_split(doc)\n",
    "        return self.pipeline(doc)\n",
    "    \n",
    "pipeline = Pipeline();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e250385f-d94b-4110-ac61-6e4a638aa02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [01:11<00:00, 69.73it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "with tqdm(total=M//2) as bar:\n",
    "    for i, (bt, tt) in enumerate(zip(biden_tweets, trump_tweets)):\n",
    "        biden_tweets[i] = pipeline(bt)\n",
    "        trump_tweets[i] = pipeline(tt)\n",
    "        bar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dafb08c-1348-4fca-bf4e-d304d67fcc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'severa biden nicki'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biden_tweets[3023]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6788113e-a737-4839-823d-5d385bb56b48",
   "metadata": {},
   "source": [
    "### Concatenate documents for vocab generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63c9ff05-9df9-4f51-91b4-f93a62e6d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = biden_tweets + trump_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c95b19c-1577-434f-ab0d-6c13f07337cb",
   "metadata": {},
   "source": [
    "## (20 pts) Task I: Train a Doc2Vec model (using the Gensim package) on tweets from the 2020 US presidential election\n",
    "\n",
    "*Docs*: \n",
    "\n",
    "* https://radimrehurek.com/gensim/models/doc2vec.html\n",
    "\n",
    "*Useful tutorials*: \n",
    "\n",
    "* https://www.kaggle.com/pierremegret/gensim-word2vec-tutorial \n",
    "* https://radimrehurek.com/gensim/auto_examples/tutorials/run_doc2vec_lee.html#sphx-glr-auto-examples-tutorials-run-doc2vec-lee-py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43e854-6a1c-432d-a125-97e10849e49d",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f67cb3d6-26c8-455f-b5e6-7f6685ba8199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change as needed\n",
    "K = 20\n",
    "word_frequency_threshold = 2\n",
    "epochs = 10\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40cb1c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import smart_open\n",
    "import gensim\n",
    "def read_corpus(text, tokens_only=False):\n",
    "        for i, line in enumerate(text):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n",
    "train_corpus = list(read_corpus(all_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27e641c1-7e76-4e15-bd86-b79b4460adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "model = Doc2Vec(vector_size=K, min_count=word_frequency_threshold, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4ad3f55-7428-4278-82e9-c7243f75498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(train_corpus)\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb31c34-61b7-49b3-a31d-ad7c742a2876",
   "metadata": {},
   "source": [
    "## (10  pts) Task II: Evaluate your model by computing the most similar documents (tweets) to new (perhaps made up) tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2729a-a9ba-4daf-ab93-06936ebd16c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template function\n",
    "def find_similar_tweets(tweet, top_n=10):\n",
    "    doc_vector = model.infer_vector(tweet)\n",
    "    sims = model.dv.most_similar([doc_vector], topn=top_n)\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1aaf0a8a-0b0c-447c-a619-96780f8a750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee6a6639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6640926640926641"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "counter = collections.Counter(ranks)\n",
    "counter[0]/(counter[0]+counter[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e0fe6e",
   "metadata": {},
   "source": [
    "### the accuracy is 0.664"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99900417-805a-415b-bbd4-ee456d1f9e5a",
   "metadata": {},
   "source": [
    "## (10 pts extra credit) Task III: Produce a scatter plot of the compressed document embeddings (2D or 3D)\n",
    "\n",
    "*Useful resources*:\n",
    "\n",
    "* http://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0afd360b-ea53-479f-bfbe-bc4f82268daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9x/2j3kgyn966ndy0nfs0m0fykr0000gn/T/ipykernel_57413/3260146044.py:3: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  docvec= model.docvecs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(random_state=1, n_iter=15000, metric=\"cosine\")\n",
    "docvec= model.docvecs\n",
    "embs = tsne.fit_transform(docvec)\n",
    "FS = (10, 8)\n",
    "fig, ax = plt.subplots(figsize=FS)\n",
    "df= pd.Data_Frame()\n",
    "df['x'] = embs[:, 0]\n",
    "df['y'] = embs[:, 1]\n",
    "ax.scatter(df.x, df.y, alpha=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "22ea507c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9x/2j3kgyn966ndy0nfs0m0fykr0000gn/T/ipykernel_57413/627624591.py:1: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
      "  type(model.docvecs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gensim.models.keyedvectors.KeyedVectors"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.docvecs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_m1] *",
   "language": "python",
   "name": "conda-env-tf_m1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
