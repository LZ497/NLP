{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f457df4-a840-4838-9b30-fc5feb2c09b5",
   "metadata": {},
   "source": [
    "# Assignment 3: Neural networks in natural language processing\n",
    "\n",
    "### Due Date: Oct 30 (both sections)\n",
    "\n",
    "### Grade (100 pts, 10%)\n",
    "\n",
    "#### Your Name: Linpei Zhang\n",
    "\n",
    "#### Your EID: Lz497\n",
    "\n",
    "*Note: This assignment covers material from the recording, notes, demo, and suggested readings from Lecture-08*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5040c21a-f813-4ce5-b5d7-bbdd59e37dcc",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369615c-54d7-4a72-bfe2-6fd84cef9582",
   "metadata": {},
   "source": [
    "### 1. Dropout (50 pts)\n",
    "\n",
    "Dropout is a regularization technique that randomly sets units in each activation layer, $a \\in \\mathbb{R}^{D}$, to zero and then multiplies the resultant vector elementwise by a constant $\\gamma$ according to:\n",
    "\n",
    "$$a_{dropout} \\leftarrow  \\gamma H \\odot a$$\n",
    "\n",
    "where $\\odot$ represents the element-wise product operator and $H \\in \\{0, 1\\}^D$ is a mask with entries drawn from \n",
    "\n",
    "$$\\begin{cases} p(0) &= p_{dropout} \\\\ p(1) &= 1 - p_{dropout} \\end{cases}$$\n",
    "\n",
    "Select a scaling factor ${\\gamma}$ that ensures the expected value over the activation layer remains invariant to the above operation, $E\\big[ a_{dropout} \\big] = E\\big[ a \\big]$, and provide rationale for your selection.\n",
    "\n",
    "*Hint: You want to show that*\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^D a_i = \\gamma \\sum_{i=1}^D a_{dropout, i}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b24261d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105115\n",
      "136011.1111111111\n",
      "gamma:1/(1-drop_prob) 1.6666666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "def dropout(a_i, drop_prob):\n",
    "    keep_prob= 1- drop_prob\n",
    "    gamma= 1/(1-drop_prob)\n",
    "    P=[drop_prob, keep_prob]\n",
    "    mask= np.random.choice([0,1],1,P)\n",
    "    return  (gamma* a_i * mask)\n",
    "\n",
    "drop_prob=0.4\n",
    "right=[]\n",
    "gamma= 1/(1-drop_prob)\n",
    "a= np.random.randint(1,1000,200)\n",
    "for i in a:\n",
    "    right.append(dropout(i,drop_prob)[0])\n",
    "print(sum(a))\n",
    "print(gamma * sum(right))\n",
    "print(\"gamma:1/(1-drop_prob)\",gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2785529-1d06-4474-8aec-baef38545787",
   "metadata": {},
   "source": [
    "### 2. Convolutions (50 pts)\n",
    "\n",
    "Consider a sequence of $T$ token embeddings, $Z \\in \\mathbb{R}^{T \\times D}$, for which $D=3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "347fcde5-c66a-4b4d-a7de-8491b5fcc513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Z = np.array([\n",
    "    [1.3,   0.4, -0.2],\n",
    "    [-3.1,  1.1,  2.1],\n",
    "    [0.9,   2.8, -1.5],\n",
    "    [1.3,   2.4,  0.1],\n",
    "    [1.0,   1.0,  0.5],\n",
    "    [3.0,  -1.4, -0.2],\n",
    "    [-0.7,  1.8,  1.3]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d3cbe3-5b3a-44aa-886f-9f56e126e04d",
   "metadata": {},
   "source": [
    "and a set of convolutional filters, $W=\\{ w^{(1)}, w^{(2)} \\}$, and corresponding filter widths $S=\\{ s^{(1)}, s^{(2)}  \\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "437d0a4d-57ea-42c9-97d1-60055b3fbfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.array([\n",
    "    [1, 1, 1],\n",
    "    [1, 1, 1]\n",
    "])\n",
    "\n",
    "w2 = np.array([\n",
    "    [2, 2, 2],\n",
    "    [2, 2, 2],\n",
    "    [2, 2, 2]\n",
    "])\n",
    "\n",
    "W = [w1, w2]\n",
    "\n",
    "S = [2, 3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6c6909-6c25-4dde-8a87-fa79b27dbf3e",
   "metadata": {},
   "source": [
    "In Lecture 08 we discussed a set of operations that maps $Z \\in \\mathbb{R}^{T \\times D}$ onto $Z' \\in \\mathbb{R}^{N_F D}$ (in this problem $N_F = 2$). This involved three steps:\n",
    "\n",
    "1. **Convolution**: The convolutional operation produces $N_F$ feature maps, $B^{(n)} \\in \\mathbb{R}^{(T - s^{(n)} + 1) \\times D}$, where $n=\\{1, \\dots, N_F\\}$, according to:\n",
    "\n",
    "$$\n",
    "\\forall_{t \\in \\{ 1, \\dots, T - s^{(n)} + 1 \\} } \\; B^{(n)}_{t,j} = \\sum_{t'=1}^{S^{(n)}} w^{(n)}_{t',j} \\; Z_{t,j}\n",
    "$$\n",
    "\n",
    "2. **Max pooling**: The max pooling operation computes the max over the sequence dimension in each feature map, $ B_{maxpool}^{(n)} \\in \\mathbb{R}^D$, according to:\n",
    "\n",
    "$$\n",
    "B_{maxpool, j}^{(n)} = \\underset{1 \\leq t' \\leq T - s^{(n)} + 1 }{\\max} B^{(n)}_{t', j}\n",
    "$$\n",
    "\n",
    "3. **Concatenation**: The resultant set of $N_F$ feature vectors are then concatenated into a single vector $Z'$ according to:\n",
    "\n",
    "$$\n",
    "Z' = \\big[ B_{maxpool}^{(1)}, \\dots, B_{maxpool}^{(n)}, \\dots,  B_{maxpool}^{(N_F)}  \\big] \\in \\mathbb{R}^{D \\cdot N_F}\n",
    "$$\n",
    "\n",
    "In the cell below, perform these three operations to produce $Z' \\in \\mathbb{R}^6$ and print it.\n",
    "\n",
    "*Hint: The max pooling operation computes the maximum over each column in $B^{(n)}$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "de28a2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### when \\ndef conv(w,s):\\n    B=[]\\n    for t in range(7-s+1):\\n        for j in range(3):\\n            for t_ in range(1):\\n                 B.append(w[t_,j]*Z[t,j]*s)\\n    return B\\nB1= np.reshape(conv(w1,S[0]),[6,3]) \\nB2= np.reshape(conv(w2,S[1]),[5,3]) \\n\\ndef pooling(B):\\n    B_pooling=[]\\n    for j in range(3):\\n        B_pooling.append(np.max(B[:,j]))\\n    return B_pooling\\n\\nB1_pooling=pooling(B1)\\nB2_pooling=pooling(B2)\\n\\nB1_pooling.extend(B2_pooling)\\n\\n'"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "### when \n",
    "def conv(w,s):\n",
    "    B=[]\n",
    "    for t in range(7-s+1):\n",
    "        for j in range(3):\n",
    "            for t_ in range(1):\n",
    "                 B.append(w[t_,j]*Z[t,j]*s)\n",
    "    return B\n",
    "B1= np.reshape(conv(w1,S[0]),[6,3]) \n",
    "B2= np.reshape(conv(w2,S[1]),[5,3]) \n",
    "\n",
    "def pooling(B):\n",
    "    B_pooling=[]\n",
    "    for j in range(3):\n",
    "        B_pooling.append(np.max(B[:,j]))\n",
    "    return B_pooling\n",
    "\n",
    "B1_pooling=pooling(B1)\n",
    "B2_pooling=pooling(B2)\n",
    "\n",
    "B1_pooling.extend(B2_pooling)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "34584e13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.0, 5.199999999999999, 1.9000000000000001, 10.6, 12.6, 3.2]"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### if S is a slide width\n",
    "\n",
    "def conv_single_step(a_slice,W):\n",
    "    \n",
    "    s= np.multiply(a_slice,W)\n",
    "    #output=np.sum(s)\n",
    "    output= s.sum(axis=0)\n",
    "    return list(output)\n",
    "\n",
    "\n",
    "def conv_forward(A_prev,w,S):\n",
    "    single_element=[]\n",
    "    (M, N) = A_prev.shape\n",
    "    s1=1 #vertical step length\n",
    "    s2=1 #horizen step length\n",
    "    (f1,f2)= w.shape\n",
    "    n_H = int((M-f1)/s1) + 1 \n",
    "    n_L =int((N-f2)/s2) + 1                            \n",
    "    for h in range(n_H):                           \n",
    "        for l in range(n_L):                                         \n",
    "            vert_start = h*s1 \n",
    "            vert_end = h*s1 + f1\n",
    "            horiz_start = l*s2 \n",
    "            horiz_end = l*s2 + f2\n",
    "            A_slice_prev = A_prev[vert_start:vert_end,horiz_start:horiz_end]\n",
    "            single_element.append(conv_single_step(A_slice_prev, w))\n",
    "    return single_element\n",
    "\n",
    "B1= conv_forward(Z,w1,S)\n",
    "B2= conv_forward(Z,w2,S)\n",
    "\n",
    "\"\"\"\n",
    "### when pooling before convolution:\n",
    "\n",
    "def max_pooling(A_prev,w,S):\n",
    "    single_element=[]\n",
    "    (M, N) = A_prev.shape\n",
    "    s1=S[0] #vertical step length\n",
    "    s2=S[1] #horizen step length\n",
    "    (f1,f2)= w.shape\n",
    "    n_H = int((M-f1)/s1) + 1 \n",
    "    n_L =int((N-f2)/s2) + 1                            \n",
    "    for h in range(n_H):                           \n",
    "        for l in range(n_L):                                         \n",
    "            vert_start = h*s1 \n",
    "            vert_end = h*s1 + f1\n",
    "            horiz_start = l*s2 \n",
    "            horiz_end = l*s2 + f2\n",
    "            A_slice_prev = A_prev[vert_start:vert_end,horiz_start:horiz_end]\n",
    "            single_element.append(np.max(A_slice_prev))\n",
    "    return single_element\n",
    "\n",
    "B1_pooling= max_pooling(Z,w1,S)\n",
    "B2_pooling= max_pooling(Z,w2,S)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "### when pooling after convolution: \n",
    "\n",
    "def maxpooling(A_prev):\n",
    "    results=[]\n",
    "    A_prev= np.reshape(A_prev,(len(A_prev),3))\n",
    "    for l in range(3):\n",
    "        results.append(np.max(A_prev[:,l]))\n",
    "    return results\n",
    "B1_pooling= maxpooling(B1)     \n",
    "B2_pooling= maxpooling(B2) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Concatenation(B1_pooling,B2_pooling):\n",
    "    Z= B1_pooling+(B2_pooling)\n",
    "    return Z\n",
    "\n",
    "Concatenation(B1_pooling,B2_pooling)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_m1] *",
   "language": "python",
   "name": "conda-env-tf_m1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
